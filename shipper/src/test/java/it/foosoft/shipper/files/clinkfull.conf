input {
    file {
#       path => "classpath:it/foosoft/shipper/files/clink.log"
       path => "C:/Users/luca/dati/logstash/**/*.gz"
    }
}

filter {
    if [message] =~ "^#" {
        drop{}
    }

    mutate {
        remove_field => [ "host", "@timestamp", "command", "path" ]
        add_field => { "cdnName" => "cdncl" }
    }

    dissect {
        mapping => {
            "message" => '%{date}	%{time}	%{ip}	%{method}	%{uri}	%{response}	%{bytesSent}	%{responseTime}	%{referer}	%{userAgentLog}	%{?cookie}	%{?disId}	%{?headerSize}	%{cache}	%{?other}'
	    }
        remove_field => [ "message" ]
    }

    mutate {
# Create a timestamp in YYYY-mm-dd HH:MM:SS", joining "date" and "time", which can be removed
        add_field => {
            "timestamp" => "%{date} %{time}"
        }
        remove_field => [ "date", "time" ]

        convert => {
          "response" => "integer"
          "responseTime" => "float"
          "bytesSent" => "integer"
        }
    }

# Here we use our newly created timestamp attribute to patch the event timestamp
    date {
        locale => "en"
        timezone => "GMT"
        match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
        remove_field => [ "timestamp" ]
    }

    uriparse {
        source => "uri"
        remove_field => [ "uri" ]
        tag_on_failure => "relurl_grok_fail"
    }

    mutate {
        copy => {
          "path" => "relativeUrl"
          "host" => "nameServer"
        }
        remove_field => ["path", "host"]
    }
}


filter {
     if [relativeUrl] =~ "^/farmunica" {
        dissect {
          mapping => {
            "relativeUrl" => "/farmunica/%{?year}/%{?month}/%{cmsId}_%{jobId}/%{assetpath}"
          }
	      convert_datatype => {
	        "cmsId" => "integer"
	      }
          tag_on_failure => "farmunica_dir_fail"
        }
        
        if [assetpath] =~ "^[\w+]*\.mp4" {
          mutate {
             add_field => {"uriType" => "mp4"}
          }
           grok {
             # Questo blocco di analisi estrae informazione dalle url Mp4
             patterns_dir => "/etc/logstash/patterns"
             tag_on_failure => "farmunica_media_match_fail"
             match => {
               "assetpath" => "(?<mp4Filename>[\w+]*\.mp4)"
             }
             id => "mp4"
           }
        } else if [assetpath] =~ "^[Hh][Ll][Ss]" {
          mutate {
             add_field => {"uriType" => "hls"}
          }
            grok {
               patterns_dir => "/etc/logstash/patterns"
               tag_on_failure => "farmunica_media_match_fail"
               break_on_match => true
               # Do the l0/xxxxx match all in one step, more efficient. first check the chunks, as they are way more frequent
               match => {  "assetpath" => "^(?<cmsTag>\w*)/(?:(?<hlsManifest>\w*\.m3u8)|(?<hlsLevel>\w*)/(?:(?<hlsLevelManifest>\w*\.m3u8)|%{INT:hlsVideoChunk:int}\.ts|%{INT:hlsAudioChunk:int}\.aac))" }
               id => "hls"
            }
        } else if [assetpath] =~ "^[Dd][Aa][Ss][Hh]" {
            mutate {
               add_field => {"uriType" => "dash"}
            }
            grok {
               # This block is for matching DASH urls
               patterns_dir => "/etc/logstash/patterns"
               tag_on_failure => "farmunica_media_match_fail"
               break_on_match => true
               match => {"assetpath" => "^(?<cmsTag>\w*)/(?:(?<dashManifest>\w*\.mpd)|dash_%{INT:adaptationSet:int}\.%{INT:representation:int}/((?<dashInit>\w*\.mp4)|%{INT:chunk:int}\.m4s))" }
               id => "dash"
           }
        } else if [assetpath] =~ "^smooth" {
                # Questo blocco di analisi estrae informazione dalle url Smooth Streaming
                mutate {
                    add_field => {"uriType" => "smooth"}
                }
                urldecode {
                    field => "assetpath"
                }
                grok {
                    patterns_dir => "/etc/logstash/patterns"
                    tag_on_failure => "farmunica_media_match_fail"
                    match => {
                        "assetpath" => "^\w*/(?:%{CMSTAG:cmsTag}.ism)(?:(?:(?:/[Qq]uality[Ll]evels\(%{QL:qualityLevel:int}\))?(?:/[Ff]ragments\(%{AV:av}(?:_%{LANG:audioLanguage})?=%{BITRATE:byteSegmentPosition:int}\))+)|/[Mm]anifest)"
                    }
                    id => "smooth"
                }
        } else {
            # Questo blocco aggiunge "unknown" a tutti i casi in cui entra si in farmunica
            # ma non è un url valido
            mutate {
                add_field => {"uriType" => "unknown"}
            }
        }
    } else if [relativeUrl] =~ "^/uhd/" {
        mutate {
          add_field => {"uriType" => "4k-uhd"}
        }
        grok {
          patterns_dir => "/etc/logstash/patterns"
          tag_on_failure => "uhd_grok_fail"
          match => {
             "relativeUrl" => "/uhd/..../\w*/?\w*/\w*/(\w*\.\d/((?:seg-(?<segment>\w*\.m4f))|(?:(?<uhdInit>\w*\.mp4)))|(?:(?<uhdManifest>\w*\.(mpd|itaeng.mpd))))"
          }
          id => "4k-uhd"
        }
    }
    mutate {
      remove_field => ["assetpath"]
    }
}

filter {
        # Geolocalizzo l'IP del Client secondo il DB free GeoLite2-City
        geoip {
            source => "ip"
            target => "src_ip"
            database => "/etc/logstash/geoloc_db/GeoIP2-City.mmdb"
        }

        # Geolocalizzo l'IP del Client secondo il DB free GeoLite2-ASN
        geoip {
            source => "ip"
            target => "src_ip"
            database => "/etc/logstash/geoloc_db/GeoIP2-ISP.mmdb"
        }

        mutate {
          add_field => { "clientIpType" => "external" }
        }

        if "_geoip_lookup_failure" not in [tags] {
            mutate {
                remove_field => ["ip"]
            }
        }
}

filter {
        # Si fa il parsing dello User Agent
        useragent {
            source => "userAgentLog"
            regexes => "/etc/logstash/patterns/regexes.yaml"
            id => "userAgent"
            target => "userAgent"
        }

        # Se il parsing dello User Agent è andato bene rimuove il campo userAgentLog
        #  che contiene la stringa catturata dai log, per risparmiare spazio
        if ([userAgent][os] !~ "Other") or
           ([userAgent][os_name] !~ "Other") or
           ([userAgent][name] !~ "Other") or
           ([userAgent][device] !~ "Other") {
            mutate {
                remove_field => ["userAgentLog"]
            }
        }
}

output {
      elasticsearch {
         hosts => [ "10.245.6.101:9200","10.245.6.102:9200","10.245.6.103:9200","10.245.6.104:9200","10.245.6.105:9200" ]
         index => "test"
         user => "logstash_writer"
         password => "F7r6u9xzv3Ccq3N2"
      }
} 
